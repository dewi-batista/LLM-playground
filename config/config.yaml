transformer:
  batch_size: 256
  d_model: 768
  lr: 1e-3
  num_blocks: 12
  num_heads: 12