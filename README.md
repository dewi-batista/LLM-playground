## Welsh Large Language Model (welsh-LLM)

### TL;DR
- GPT-2 XL-style language model trained specifically for Welsh
- Personal project to develop hands-on experience with modern LLM training

This repository contains my work on training a Welsh language model. Welsh is a low-resource language with relatively little prior LLM work, making it a useful setting for experimenting with contemporary language-model training methods.

### Progress roadmap
- [x] Tokeniser
- [x] Pre-training
- [x] Supervised fine-tuning
- [x] Streaming capabilities for larger training corpora
- [x] Evaluation (perplexity-based and qualitative sampling)
- [ ] Instruction tuning and prompt formatting
- [ ] RL-based alignment (e.g. preference optimisation / RLHF-style methods)
- [ ] Safety filtering and dataset curation
