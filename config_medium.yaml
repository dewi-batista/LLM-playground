transformer:
  batch_size: 100
  d_model: 1024
  dropout: 0.1
  early_stop_delta: 0.02
  early_stop_pat: 10
  eval_batches: 50
  eval_every: 500
  grad_checkpoint: false
  grad_accum_steps: 1
  grad_clip: 1.0
  lr: 1.5e-4
  min_count: 5
  num_blocks: 24
  seq_len: 256
  train_tokens: 5e10
  val_frac: 0.1
  warmup_frac: 0.02
  weight_decay: 0.01

sft:
  batch_size: 100
  seq_len: 256
  dropout: 0.1
  early_stop_delta: 0.1
  early_stop_pat: 10
  eval_batches: 50
  eval_every: 100
  grad_checkpoint: false
  grad_accum_steps: 1
  grad_clip: 1.0
  lr: 5.0e-5
  train_tokens: 1e8
  val_frac: 0.1
  warmup_frac: 0.02
  weight_decay: 0.0
